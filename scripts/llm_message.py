import pandas as pd
import numpy as np
from openai import OpenAI
import json
import os
import time

#generate personalized message based on the guesses generated by the llm

#get api key
with open("data/api_key.json",'r') as f:
    keys = json.load(f)
client = OpenAI(api_key=keys['api_key'])

#function to prompt model to generate the personalized message
def generate_message(guess,explanation,pid,vector_store_id,prompt_path,reasoning=False):
    with open(prompt_path, 'r') as f:
        prompt = f.read()
    prompt = prompt + f"\nuser ID: {pid}, guess: {guess}, explanation for guess: {explanation}"
    num_tries = 0
    while num_tries < 2:
        print(f"Generating Response for {pid} (try {num_tries+1})")
        try:
            if reasoning:
                pass
            else:
                response = client.responses.create(
                    model="gpt-5",
                    input=prompt,
                    tools=[{
                    "type": "file_search",
                    "vector_store_ids": [vector_store_id]
                    }]
                )
            print("Response Complete")
            return {"pid":pid,"message":response.output_text}
            
        except Exception as e:
            print(f"Rate limit hit, waiting 60 seconds... ({e})")
            time.sleep(60)
            num_tries = num_tries + 1
    print(f"Failed to generate output for {pid}")
    
#main function to loop through all users and generate messages
def message_all_users(guesses_df,vector_store_id,prompt_path,reasoning=False):
    for i, row in guesses_df.iterrows():
        if reasoning:
            outfile = "saved_output/llm_responses/reasoning_messages.csv"
        else:
            outfile = "saved_output/llm_responses/data_only_messages_all.csv"
            response = generate_message(row['guess'],row['explanation'],row['pid'],vector_store_id, prompt_path)

        # convert to DataFrame row
        df_row = pd.DataFrame([response])

        # append to csv
        if i == 0 and not os.path.exists(outfile):
            df_row.to_csv(outfile, index=False, mode="w")   # first write, include header
        else:
            df_row.to_csv(outfile, index=False, mode="a", header=False)  # append without header

        print(f"Saved response for {row['pid']}")


if __name__ == "__main__":
    vector_store_id = json.load(open("data/vector_store_id.json"))["knowledge_base"]
    guesses_df = pd.read_csv("saved_output/llm_responses/data_only_guesses.csv")
    prompt_path = "prompts/message_prompt.txt"
    message_all_users(guesses_df,vector_store_id,prompt_path)
